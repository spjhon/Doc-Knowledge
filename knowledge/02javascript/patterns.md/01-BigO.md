---
sidebar_position: 1
---

# The big O

**The O stands for Order:**

Todas las estructuras de datos tienen siempre alg√∫n par√°metro b√°sico del cual depende la eficiencia de todos los algoritmos. Por ejemplo, si est√°s buscando en un diccionario, el n√∫mero de claves en el diccionario probablemente afectar√° la velocidad de b√∫squeda; a m√°s claves, m√°s tiempo. Si se ordena un conjunto de valores, tener m√°s valores significa una ordenaci√≥n m√°s lenta; por ejemplo, ordenar las 5 cartas de una mano de p√≥ker se puede hacer muy r√°pido, pero ordenar un mazo completo de 52 cartas toma m√°s tiempo.

En todos los casos, llamaremos a ese par√°metro de entrada , y expresar√°s la complejidad de tiempo del algoritmo como una funci√≥n de esa entrada; esto es el **an√°lisis de algoritmos**. Un algoritmo ser√° m√°s eficiente cuando los valores de esa funci√≥n sean peque√±os o, al menos, cuando crezca lentamente en comparaci√≥n con el crecimiento del tama√±o de la entrada.

En algunos casos, el rendimiento de un algoritmo puede estar directamente vinculado a los datos en s√≠; por ejemplo, ordenar una secuencia que est√° casi en orden es probablemente m√°s r√°pido que ordenar una secuencia de valores completamente desordenada y aleatoria. Esto significa que consideraremos el rendimiento en el **mejor caso** (*best-case*), en el **peor caso** (*worst-case*), as√≠ como el **rendimiento promedio** (*average performance*). Si no se especifica nada, buscaremos un **l√≠mite superior** (*upper bound*) para la complejidad del algoritmo, por lo que en este libro analizaremos la complejidad en el peor de los casos, a menos que se indique lo contrario.

Puntos clave para recordar:

* **La variable :** Siempre representa el tama√±o de lo que est√°s procesando (elementos en un array, caracteres en un texto, nodos en un √°rbol).
* **¬øPor qu√© el "peor caso"?** En ingenier√≠a de software, preferimos saber qu√© es lo m√°s lento que podr√≠a llegar a ser un programa para garantizar que el sistema no colapse bajo presi√≥n. Es como planificar un viaje: te preparas para el tiempo que tardar√≠as si hay mucho tr√°fico, no si todas las luces est√°n en verde.

Informaci√≥n extra√≠da mas que todo del libro: **JavaScript Data Structures and Algorithms An Introduction to Understanding and Implementing Core Data Structure and Algorithm Fundamentals. Por, Sammie Bae**

Mide el peor caso para un algoritmo que involucra tiempo y memoria.

n representa el numero de inputs y la pregunta es cuando ese n tiende al infinito, que se hace?

Claro üëç Aqu√≠ tienes la **tabla traducida al espa√±ol**, **bien formateada** y con los conceptos claros.

**Tabla 4-2: √ìrdenes de complejidad m√°s comunes:**

| Orden          | Nombre      | Ejemplo                                                                                                                      |
| -------------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------- |
| **O(1)**       | Constante   | Acceder al primer elemento de una lista y hacer `pop` al tope de una pila (Cap√≠tulo 10)                                      |
| **O(log n)**   | Logar√≠tmico | Buscar en un arreglo ordenado usando b√∫squeda binaria (Cap√≠tulo 9) y la altura promedio de un √°rbol binario (Cap√≠tulo 12)    |
| **O(n)**       | Lineal      | Buscar en un arreglo no ordenado (Cap√≠tulo 9) y recorrido **inorder** de un √°rbol (Cap√≠tulo 12)                              |
| **O(n log n)** | Log-lineal  | Ordenar un arreglo con **heapsort** y el comportamiento promedio de **quicksort** (Cap√≠tulo 6)                               |
| **O(n¬≤)**      | Cuadr√°tica  | Ordenar un arreglo con **bubble sort** y el peor caso de **quicksort** (Cap√≠tulo 6)                                          |
| **O(k‚Åø)**      | Exponencial | Verificar si una f√≥rmula binaria es una tautolog√≠a (k = 2) y una implementaci√≥n ingenua de la serie de Fibonacci (k ‚âà 1.618) |
| **O(n!)**      | Factorial   | Encontrar la soluci√≥n √≥ptima del problema del **viajero (TSP)** y ordenar mediante permutaciones aleatorias (Cap√≠tulo 6)     |

üìå Nota r√°pida para entenderla mejor

* De **O(1)** a **O(n log n)** ‚Üí generalmente **aceptable**
* **O(n¬≤)** ‚Üí puede ser lento con datos grandes
* **O(k‚Åø)** y **O(n!)** ‚Üí **impracticables** para tama√±os grandes

## 1. Rules

"Representemos la complejidad de un algoritmo como f(n). n representa el n√∫mero de entradas, f(n)tiempo‚Äã representa el tiempo necesario y f(n)espacio‚Äã representa el espacio (memoria adicional) que el algoritmo requiere. El objetivo del an√°lisis de algoritmos es comprender su eficiencia calculando f(n). Sin embargo, calcular f(n) puede ser un desaf√≠o. La notaci√≥n Big-O proporciona algunas reglas fundamentales que ayudan a los desarrolladores a computar f(n):

### 1.1. Coefficient Rule: ‚ÄúGet Rid of Constants‚Äù

Regla del coeficiente: Si f(n) es O(g(n)), entonces kf(n) es O(g(n)), para cualquier constante k>0. Esta regla elimina los coeficientes que no est√°n relacionados con el tama√±o de la entrada, n. Esto se debe a que, a medida que n se acerca al infinito, el otro coeficiente se vuelve insignificante.

La idea es eliminar las constantes y datos que no dependan del numero de entradas n.

* This means that both 5f(n) and f(n) have the same Big-O notation of O(f(n)).

Aqu√≠ tienes un ejemplo de un bloque de c√≥digo con una complejidad de tiempo de O(n):

```javascript
1 function a(n) {
2   var count = 0;
3   for (var i = 0; i < n; i++) {
4     count += 1;
5   }
6   return count;
7 }

```

Este bloque de c√≥digo tiene una f(n)=n. Esto se debe a que suma a count n veces. Por lo tanto, esta funci√≥n es O(n) en complejidad de tiempo.

```javascript
1 function a(n) {
2   var count = 0;
3   for (var i = 0; i < 5 * n; i++) {
4     count += 1;
5   }
6   return count;
7 }

```

Este bloque tiene una f(n)=5n. Esto se debe a que se ejecuta desde 0 hasta 5n. Sin embargo, los dos primeros ejemplos tienen una notaci√≥n Big-O de O(n)."

¬øPor qu√© ambos son O(n)?

Como mencionaba el texto anterior sobre la Regla del Coeficiente, en el an√°lisis de algoritmos ignoramos las constantes.

* En el primer caso, tienes 1n.
* En el segundo caso, tienes 5n.

**Desde el punto de vista de Big-O, lo que importa es que si n se duplica, el tiempo de ejecuci√≥n tambi√©n se duplica (crecimiento lineal). No importa si uno es 5 veces m√°s lento que el otro; ambos pertenecen a la misma "familia" de velocidad.**

El siguiente bloque de c√≥digo muestra otra funci√≥n con una complejidad de tiempo lineal, pero con una operaci√≥n adicional en la l√≠nea 6:

```js
1 function a(n){
2   var count = 0;
3   for (var i = 0; i < n; i++){
4     count += 1;
5   }
6   count += 3;
7   return count;
8 }
```

Por √∫ltimo, este bloque de c√≥digo tiene una f(n)=n+1. Hay un +1 debido a la √∫ltima operaci√≥n (count += 3). Esto todav√≠a tiene una notaci√≥n Big-O de O(n). Esto se debe a que esa operaci√≥n √∫nica no depende de la entrada n. A medida que n se acerca al infinito, dicha operaci√≥n se vuelve insignificante."

¬øPor qu√© count += 3 es solo +1?

En el an√°lisis de algoritmos, no contamos el valor que sumas (el n√∫mero 3), sino la cantidad de instrucciones que el procesador debe ejecutar.

* El bucle for ejecuta la l√≠nea 4 n veces.
* La l√≠nea 6 se ejecuta 1 sola vez, sin importar si n es diez o diez millones.

Resumen de la "limpieza" de Big-O:

Para obtener el Big-O final de cualquier funci√≥n, aplicamos estos dos pasos:

* Eliminar las constantes: n+1 se convierte en n.
* Eliminar los coeficientes: 5n se convierte en n.

De ah√≠ que, para los cient√≠ficos de la computaci√≥n, un algoritmo que hace n pasos, uno que hace 5n y uno que hace n+100 son todos, en esencia, igual de eficientes: son O(n).

### 1.2. Sum Rule: ‚ÄúAdd Big-Os Up‚Äù

Regla de la suma: Si f(n) es O(h(n)) y g(n) es O(p(n)), entonces f(n)+g(n) es O(h(n)+p(n)). Simplemente establece que si una complejidad de tiempo resultante es la suma de dos complejidades diferentes, la notaci√≥n Big-O resultante es tambi√©n la suma de ambas.

Lo que dice es que si un algoritmo esta compuesto por algoritmos mas peque√±os, estos se pueden sumar normalmente, despues por supuesto de eliminar las constantes y coeficientes.

```js
1 function a(n){
2 var count =0;
3 for (var i=0;i<n;i++){
4 count+=1;
5 }
6 for (var i=0;i<5*n;i++){
7 count+=1;
8 }
9 return count;
10 }
```

In this example, line 4 has f(n) = n, and line 7 has f(n) = 5n. This results in 6n. However, when applying the coefficient rule, the final result is O(n) = n.

### 1.3. Product Rule: ‚ÄúMultiply Big-Os‚Äù

Regla del producto: Si f(n) es O(h(n)) y g(n) es O(p(n)), entonces f(n)g(n) es O(h(n)p(n)). De manera similar, la Big-O se multiplica cuando las complejidades de tiempo se multiplican.

Esta es la regla que indica que el exonencial sube a medida que se anida el codigo especialmente en loops

```js
1 function (n){
2 var count =0;
3 for (var i=0;i<n;i++){
4 count+=1;
5 for (var i=0;i<5*n;i++){
6 count+=1;
7 }
8 }
9 return count;
10 }
```

In this example, f(n) = 5n*n because line 7 runs 5n times for a total of n iterations. Therefore, this results in a total of 5n2 operations. Applying the coefficient rule, the result is that O(n)=n2.

### 1.4. Polynomial Rule: ‚ÄúBig-O to the Power of k‚Äù

Regla polin√≥mica: Si f(n) es un polinomio de grado k, entonces f(n) es O(nk). Intuitivamente, establece que las complejidades polin√≥micas tienen una Big-O del mismo grado polin√≥mico.

```js
1 function a(n){
2 var count =0;
3 for (var i=0;i<n*n;i++){
4 count+=1;
5 }
6 return count;
7 }
```

In this example, f(n) = nÀÜ2 because line 4 runs n*n iterations.

### 1.5. Otras reglas

* Regla transitiva: Si f(n) es O(g(n)) y g(n) es O(h(n)), entonces f(n) es O(h(n)). Es una forma sencilla de decir que la misma complejidad de tiempo tiene la misma Big-O.

* Regla del logaritmo de una potencia: log(nk) es O(logn) para cualquier constante k>0. Con esta regla, las constantes dentro de una funci√≥n logar√≠tmica tambi√©n se ignoran en la notaci√≥n Big-O.

Se debe prestar especial atenci√≥n a las tres primeras reglas y a la regla polin√≥mica, ya que son las m√°s utilizadas. Analizar√© cada una de esas reglas en las siguientes secciones."

Concepto clave: El "Infinito"

Como menciona el texto en la Regla del Coeficiente, en programaci√≥n no nos importa si un algoritmo tarda 2n o 5n. Lo que nos importa es que crece de forma lineal. Cuando n (la cantidad de datos) es un n√∫mero gigantesco como un bill√≥n, el hecho de que est√© multiplicado por 2 o por 5 deja de ser relevante comparado con la velocidad a la que crece la funci√≥n.

Lo que se mide es **TIME COMPLEXITY Y SPACE COMPLEXITY**

El espacio se tiene en cuenta cuando se necesita crear espacios en memoria adiconales por cada operacion lo cual conlleva a gastar recursos de memoria.

## 2. Big O en Algoritmos Recursivos
